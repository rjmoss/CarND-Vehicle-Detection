{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "\n",
    "from utils import extract_features_many_filenames\n",
    "\n",
    "# NOTE: the next import is only valid for scikit-learn version <= 0.17\n",
    "# for scikit-learn >= 0.18 use:\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook classifier.ipynb to script\n",
      "[NbConvertApp] Writing 4136 bytes to classifier.py\n"
     ]
    }
   ],
   "source": [
    "# To save as normal python script (easier to git diff)\n",
    "!jupyter nbconvert --to script classifier.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_folders = {\n",
    "    'vehicles': [\n",
    "        'KITTI_extracted',\n",
    "        'GTI_Right',\n",
    "        'GTI_MiddleClose',\n",
    "        'GTI_Left',\n",
    "        'GTI_Far'\n",
    "    ],\n",
    "    'non-vehicles': [\n",
    "        'GTI',\n",
    "        'Extras'\n",
    "    ]\n",
    "}\n",
    "\n",
    "training_filenames = {\n",
    "    'vehicles': [],\n",
    "    'non-vehicles': []\n",
    "}\n",
    "\n",
    "for folder, subfolders in training_folders.items():\n",
    "    for subfolder in subfolders:\n",
    "        files = glob.glob(folder + '/' + subfolder + '/' + '*.png')\n",
    "        training_filenames[folder].extend(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "    # Load image\n",
    "    # Extract features from image\n",
    "    # Add features to training set\n",
    "    # Preprocess data (might not be here?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smaller sample size while preparing pipeline\n",
    "# sample_size = 500\n",
    "# training_filenames['vehicles'] = training_filenames['vehicles'][0:sample_size]\n",
    "# training_filenames['non-vehicles'] = training_filenames['non-vehicles'][0:sample_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "color_space = 'LUV' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 9  # HOG orientations\n",
    "pix_per_cell = 8 # HOG pixels per cell\n",
    "cell_per_block = 2 # HOG cells per block\n",
    "hog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (16, 16) # Spatial binning dimensions\n",
    "hist_bins = 16    # Number of histogram bins\n",
    "spatial_feat = True # Spatial features on or off\n",
    "hist_feat = False # Histogram features on or off\n",
    "hog_feat = False # HOG features on or off\n",
    "y_start_stop = [400, 700] # Min and max in y to search in slide_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8792, 768) (8968, 768)\n",
      "Feature vector length: 768\n",
      "CPU times: user 23.1 s, sys: 4.45 s, total: 27.6 s\n",
      "Wall time: 3min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Feature extraction and preparation\n",
    "car_features = extract_features_many_filenames(training_filenames['vehicles'], color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "notcar_features = extract_features_many_filenames(training_filenames['non-vehicles'], color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "\n",
    "print(np.asarray(car_features).shape, np.asarray(notcar_features).shape)\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2)\n",
    "\n",
    "print('Feature vector length:', len(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of SVC =  0.9133\n",
      "CPU times: user 17.6 s, sys: 252 ms, total: 17.9 s\n",
      "Wall time: 19.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create the classifier\n",
    "svc = LinearSVC()\n",
    "\n",
    "# Train the classifier\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Classifier accuracy\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the classifier\n",
    "pickle.dump(svc, open('svc_classifier.pkl', 'wb'))\n",
    "# Load with:\n",
    "# clf = joblib.load('filename.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
